# CRUD-RAG 数据集使用说明

## 数据集概述

CRUD-RAG是一个全面的中文RAG基准测试数据集,专门用于评测检索增强生成(RAG)系统的性能。

下载位置: `./CRUD_RAG/`

## 数据集结构

### 1. 评测数据集
- 位置: `data/crud/merged.json` (118MB)
- 内容: 包含事件摘要、问答对等评测数据
- 用途: 用于评测RAG系统的召回率、精确率等指标

### 2. 文档库 (80,000+篇新闻文档)
- 位置: `data/80000_docs/`
- 内容: 超过80,000篇中文新闻文档,涵盖多个领域
  - 政治新闻
  - 经济新闻
  - 社会新闻
  - 科技新闻
  - 文化新闻
- 格式: 文本文件,每篇文档包含发布时间和正文
- 用途: 作为RAG系统的检索文档库

### 3. 评测脚本
- `evaluator.py`: 评测工具
- `quick_start.py`: 快速开始脚本
- `src/`: 源代码目录

## 使用方法

### 方案一: 直接使用CRUD-RAG的评测框架

1. 安装依赖
```bash
cd CRUD_RAG
pip install -r requirements.txt
```

2. 启动milvus-lite服务
```bash
milvus-server
```

3. 运行评测
```bash
python quick_start.py \
  --model_name 'gpt-3.5-turbo' \
  --data_path 'data/crud/merged.json' \
  --docs_path 'data/80000_docs' \
  --task 'all'
```

### 方案二: 将数据导入Dify进行评测

#### 步骤1: 准备文档库
将`data/80000_docs/`目录下的文档上传到Dify知识库:
- 可以选择部分文档(如前1000篇)进行测试
- 建议创建3个知识库,分别使用不同的分块策略:
  - 通用分块
  - 父子分块
  - QA分块

#### 步骤2: 创建评测集
从`data/crud/merged.json`中提取问答对,转换成评测集格式:

| id | query | gold_doc_id | gold_chunk_text | category | difficulty |
|----|-------|-------------|-----------------|----------|------------|
| 1  | 问题1 | doc_001     | 答案文本...     | 新闻     | easy       |

#### 步骤3: 运行评测
使用`rag_evaluator.py`脚本进行评测

## 推荐使用方式

### 快速测试方案
1. 选择1000篇文档: 从80000_docs中选择前1000篇
2. 上传到Dify: 创建测试知识库
3. 生成评测集: 使用`build_evaluation_set.py`从知识库自动生成候选问题
4. 人工审核: 筛选出50-100个高质量的问答对
5. 运行评测: 测试不同配置

### 完整评测方案
1. 使用全部80000篇文档
2. 创建3个知识库(不同分块策略)
3. 准备300-500个评测问题
4. 批量对比评测
5. 生成可视化报告

## 数据集特点

- 规模大: 80,000+篇真实新闻文档
- 领域广: 涵盖政治、经济、社会、科技等多个领域
- 质量高: 来自权威新闻源,内容真实可靠
- 适合中文: 专门为中文RAG系统设计
- 开箱即用: 提供完整的评测框架和脚本

## 下一步建议

1. 先小规模测试: 选择100-1000篇文档进行初步测试
2. 验证流程: 确保整个评测流程能够跑通
3. 扩大规模: 逐步增加文档数量和评测集规模
4. 对比分析: 测试不同分块策略和参数配置

---

注意: 这个数据集适合RAG评测需求,可以直接用来测试Dify知识库的检索效果。
